{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Logistic Regression Classifier from scratch using python code..\n",
    "# yhat=(exp(b0+b1x1+b2x2-----)/1+exp(b0+b1x1+b2x2-----))\n",
    "# Most simplfied yhat=1/(1+exp(-(b0+b1x1+b2x2-----)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "from csv import reader\n",
    "def load_csv(filename):\n",
    "    dataset=list()\n",
    "    open_file=open(filename)\n",
    "    read_file=reader(open_file)\n",
    "    for row in read_file:\n",
    "        if not row:\n",
    "            continue\n",
    "        dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting String column values to float values\n",
    "def convert_str_to_float(dataset,column):\n",
    "    for row in dataset:\n",
    "        row[column]=float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Statistics finding min and max values for each attribute\n",
    "def minmax(dataset):\n",
    "    minmax=list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        column_value=[row[i] for row in dataset]\n",
    "        min_value=min(column_value)\n",
    "        max_value=max(column_value)\n",
    "        minmax.append([min_value,max_value])\n",
    "    return minmax        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Statistics Normalizing the dataset\n",
    "def normalize_scale(dataset,minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i]=(row[i]-minmax[i][0])/(minmax[i][1]-minmax[i][0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Statistics building Model Accuracy using KFold Cross validation technique\n",
    "from random import seed\n",
    "from random import randrange\n",
    "def KFold(dataset,folds):\n",
    "    fold_values=list()\n",
    "    dataset_copy=list(dataset)\n",
    "    fold_size=int(len(dataset)/folds)\n",
    "    for _ in range(folds):\n",
    "        fold=list()\n",
    "        while len(fold)<fold_size:\n",
    "            index=randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        fold_values.append(fold)\n",
    "    return fold_values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Statistics Building Model Accuracy metrics prediction using classification accuracy technique\n",
    "def accuracy_metrics(actual,predicted):\n",
    "    correct=0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i]==predicted[i]:\n",
    "            correct+=1\n",
    "    return correct/float(len(actual))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicte model values\n",
    "from math import exp\n",
    "def predict(row,coeff):\n",
    "    yhat=coeff[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat+=coeff[i+1]*row[i]\n",
    "    return 1.0/(1.0+exp(-yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find coefficient from train data using stochastic gradient descent technique\n",
    "def coefficient_sgd(train,learning_rate,epoch):\n",
    "    coeff=[0.0 for row in range(len(dataset[0]))]\n",
    "    for _ in range(epoch):\n",
    "        for row in train:\n",
    "            yhat=predict(row,coeff)\n",
    "            error=row[-1]-yhat\n",
    "            coeff[0]=coeff[0]+learning_rate*error*yhat*(1.0-yhat)\n",
    "            for i in range(len(row)-1):\n",
    "                coeff[i+1]=coeff[i+1]+learning_rate*error*yhat*(1.0-yhat)*row[i]\n",
    "    return coeff           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model accuracy\n",
    "def evaluate_model(dataset,algorithm,folds,*args):\n",
    "    folds=KFold(dataset,folds)\n",
    "    accuracy=list()\n",
    "    for fold in folds:\n",
    "        train_set=list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set=sum(train_set,[])\n",
    "        test_set=list()\n",
    "        for row in fold:\n",
    "            row_copy=list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1]=None\n",
    "        predict=algorithm(train_set,test_set,*args)\n",
    "        actual=[row[-1] for row in fold]\n",
    "        classification_accuracy=accuracy_metrics(actual,predict)\n",
    "        accuracy.append(classification_accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression Algorithm \n",
    "def logisitic_regression_classifier(train,test,learning_rate,epoch):\n",
    "    predicted=list()\n",
    "    coeff=coefficient_sgd(train,learning_rate,epoch)\n",
    "    for row in test:\n",
    "        yhat=predict(row,coeff)\n",
    "        yhat=round(yhat)\n",
    "        predicted.append(yhat)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression classifier for pima indian diabets sample dataset\n",
    "seed(1)\n",
    "filename='pima-indians-diabetes.csv'\n",
    "dataset=load_csv(filename)\n",
    "for column in range(len(dataset[0])):\n",
    "    convert_str_to_float(dataset,column)\n",
    "data_minmax=minmax(dataset)\n",
    "normalize_scale(dataset,data_minmax)\n",
    "l_rate=0.1\n",
    "epoch=100\n",
    "folds=5\n",
    "accuracy=evaluate_model(dataset,logisitic_regression_classifier,folds,l_rate,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73.20261437908496, 75.81699346405229, 75.81699346405229, 83.66013071895425, 78.43137254901961]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean_accuracy:', 77.38562091503267)\n"
     ]
    }
   ],
   "source": [
    "print(\"mean_accuracy:\",(sum(accuracy)/float(len(accuracy))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
