{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Naive Bayes classifier algorithm for iris flower species case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file\n",
    "from csv import reader\n",
    "def load_csv(filename):\n",
    "    dataset=list()\n",
    "    open_file=open(filename)\n",
    "    read_file=reader(open_file)\n",
    "    for row in read_file:\n",
    "        if not row:\n",
    "            continue\n",
    "        dataset.append(row)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting String column values to float values\n",
    "def convert_str_to_float(dataset,column):\n",
    "    for row in dataset:\n",
    "        row[column]=float(row[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical value into string integer value\n",
    "def convert_str_to_int(dataset,column):\n",
    "    class_value=[row[column] for row in dataset]\n",
    "    unique=set(class_value)\n",
    "    unique_value=dict()\n",
    "    for i,value in enumerate(unique):\n",
    "        unique_value[value]=i\n",
    "    for row in dataset:\n",
    "        row[column]=unique_value[row[column]]\n",
    "    return unique_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding min and max values for each attribute or column\n",
    "def column_minmax(dataset):\n",
    "    minmax=list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        column_values=[row[i] for row in dataset]\n",
    "        min_value=min(column_values)\n",
    "        max_value=max(column_values)\n",
    "        minmax.append([min_value,max_value])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nomalizing our dataset using normalize scale technique\n",
    "def normalize_scale(dataset,minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i]=(row[i]-minmax[i][0])/(minmax[i][1]-minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating accuracy of an algorithm\n",
    "def classification_accuracy(actual,predicted):\n",
    "    correct=0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i]==predicted[i]:\n",
    "            correct+=1\n",
    "    return correct/float(len(actual))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model accuracy by KFold crossvalidation data split technique\n",
    "from random import seed\n",
    "from random import randrange\n",
    "def KFold(dataset,folds):\n",
    "    fold_values=list()\n",
    "    dataset_copy=list(dataset)\n",
    "    fold_size=int(len(dataset)/folds)\n",
    "    for _ in range(folds):\n",
    "        fold=list()\n",
    "        while len(fold)<fold_size:\n",
    "            index=randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        fold_values.append(fold)\n",
    "    return fold_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate accuracy of model\n",
    "def evaluate_model(dataset,algorithm,folds,*args):\n",
    "    folds=KFold(dataset,folds)\n",
    "    predictions=list()\n",
    "    for fold in folds:\n",
    "        train_set=list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set=sum(train_set,[])\n",
    "        test_set=list()\n",
    "        for row in fold:\n",
    "            row_copy=list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1]=None\n",
    "        predicted=algorithm(train_set,test_set,*args)\n",
    "        actual=[row[-1] for row in fold]\n",
    "        accuracy=classification_accuracy(actual,predicted)\n",
    "        predictions.append(accuracy)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Naive Bayes classification algorithm for Iris Flower Species case study\n",
    "def naive_bayes_classification(train,test):\n",
    "    predictions=list()\n",
    "    # split dataset by class values and calculate statistics for each row\n",
    "    summarize=summarize_by_class(train)\n",
    "    for row in test:\n",
    "        # Getting predictions for test data based on trained model\n",
    "        predict=predicted(summarize,row)\n",
    "        predictions.append(predict)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by class values then calculate statistics for each row\n",
    "def summarize_by_class(train):\n",
    "    # Separate dataset by class values and store all values in dictionary\n",
    "    summarize=dict()\n",
    "    separate=separate_by_class(train)\n",
    "    # Calculate Statistics for each row\n",
    "    for class_value,value in separate.items():\n",
    "        summarize[class_value]=summarize_dataset(value)\n",
    "    return summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset by class values\n",
    "def separate_by_class(train):\n",
    "    # Storing all separated class values in dictionary\n",
    "    separate=dict()\n",
    "    # split train dataset one by one row and store class values separatly \n",
    "    # Make one list for each class value\n",
    "    # Store all those values in dictionary\n",
    "    for i in range(len(train)):\n",
    "        vector=train[i]\n",
    "        class_value=vector[-1]\n",
    "        if (class_value not in separate):\n",
    "            separate[class_value]=list()\n",
    "        separate[class_value].append(vector)\n",
    "    return separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean, standard deviation and count for each column\n",
    "def summarize_dataset(value):\n",
    "    summarize=[(mean(column),std_dev(column),len(column) )for column in zip(*value)]\n",
    "    del(summarize[-1])\n",
    "    return summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean for each column\n",
    "def mean(column):\n",
    "    return sum(column)/float(len(column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation for each column\n",
    "from math import sqrt\n",
    "def std_dev(column):\n",
    "    variance=sum([(x-mean(column))**2 for x in column])/float(len(column)-1)\n",
    "    return sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class for a given row\n",
    "def predicted(summarize,row):\n",
    "    probabilities=calculate_class_probabilities(summarize,row)\n",
    "    best_label,best_prob=None,-1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probabilities.items():\n",
    "            best_prob=probability\n",
    "            best_label=class_value\n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries,row):\n",
    "    total_rows=sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities=dict()\n",
    "    for class_value,class_summaries in summaries.items():\n",
    "        probabilities[class_value]=summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean,stdev,_=class_summaries[i]\n",
    "            probabilities[class_value]*=calculate_probability(row[i],mean,stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the gaussian probability distribution funtion for x\n",
    "from math import exp\n",
    "from math import pi\n",
    "def calculate_probability(x,mean,stdev):\n",
    "    exponent=exp(-((x-mean)**2/(2*stdev**2)))\n",
    "    return (1/(sqrt(2*pi)*stdev))*exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30.0, 30.0, 50.0, 33.33333333333333, 20.0]\n"
     ]
    }
   ],
   "source": [
    "# test Navie bayes on iris dataset\n",
    "from random import seed\n",
    "seed(1)\n",
    "filename='iris.csv'\n",
    "dataset=load_csv(filename)\n",
    "convert_str_to_int(dataset,-1)\n",
    "for i in range(len(dataset[0])):\n",
    "    convert_str_to_float(dataset,i)\n",
    "minmax=column_minmax(dataset)\n",
    "normalize_scale(dataset,minmax)\n",
    "folds=5\n",
    "accuracy=evaluate_model(dataset,naive_bayes_classification,folds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Means Accuracy of an algorithm', 32.666666666666664)\n"
     ]
    }
   ],
   "source": [
    "# Mean accuracy of a model\n",
    "print(\"Means Accuracy of an algorithm\",sum(accuracy)/float(len(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
